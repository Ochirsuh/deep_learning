{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchinfo import summary as Model_Summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 74954\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.padding1 = nn.ZeroPad2d(1)\n",
    "        self.fc1 = nn.Linear(64*2*2, 64)             \n",
    "        self.fc2 = nn.Linear(64, 10)                  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.padding1(x)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, 64*2*2)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000] loss: 2.300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\ojro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ojro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(5): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # Print every 1000 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 1000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "InceptionV1 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, In_Channels, Out_Channels, Kernel_Size, Stride, Padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.Conv = nn.Conv2d(in_channels=In_Channels, out_channels=Out_Channels, kernel_size=Kernel_Size, stride=Stride, padding=Padding)\n",
    "        self.Batch_Norm = nn.BatchNorm2d(num_features=Out_Channels)\n",
    "        self.Activ_Func = nn.ReLU()\n",
    "   \n",
    "    def forward(self, Tensor_Path):\n",
    "        Tensor_Path = self.Conv(Tensor_Path)\n",
    "        Tensor_Path = self.Batch_Norm(Tensor_Path)\n",
    "        Tensor_Path = self.Activ_Func(Tensor_Path)\n",
    "        \n",
    "        return Tensor_Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 128, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "Random_Tensor = torch.randn(5, 3, 224, 224) #Санамсаргүй байдлаар Тенсорыг үүсгэв.\n",
    "Test_ConvBlock = ConvBlock(In_Channels=3, Out_Channels=128, Kernel_Size=(3,3), Stride=(1,1), Padding=(1,1))\n",
    "print(Test_ConvBlock(Random_Tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Inception Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self,In_Channels, Num_Of_Filters_1x1, Num_Of_Filters_3x3, Num_Of_Filters_5x5, Num_Of_Filters_3x3_Reduce,Num_Of_Filters_5x5_Reduce, Pooling):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.Block_1 = nn.Sequential(ConvBlock(In_Channels=In_Channels, Out_Channels=Num_Of_Filters_1x1, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0)))\n",
    "        \n",
    "        self.Block_2 = nn.Sequential(\n",
    "            ConvBlock(In_Channels=In_Channels, Out_Channels= Num_Of_Filters_3x3_Reduce, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0)),\n",
    "            ConvBlock(In_Channels=Num_Of_Filters_3x3_Reduce, Out_Channels= Num_Of_Filters_3x3, Kernel_Size=(3,3), Stride=(1,1), Padding=(1,1))\n",
    "        )\n",
    "        \n",
    "        self.Block_3 = nn.Sequential(\n",
    "            ConvBlock(In_Channels=In_Channels, Out_Channels= Num_Of_Filters_5x5_Reduce, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0)),\n",
    "            ConvBlock(In_Channels=Num_Of_Filters_5x5_Reduce, Out_Channels= Num_Of_Filters_5x5, Kernel_Size=(5,5), Stride=(1,1), Padding=(2,2))\n",
    "        )\n",
    "        \n",
    "        self.Block_4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            ConvBlock(In_Channels=In_Channels, Out_Channels=Pooling, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0))\n",
    "        )\n",
    "    def forward(self, Tensor_Path):\n",
    "        First_Block_Out = self.Block_1(Tensor_Path)\n",
    "        Second_Block_Out = self.Block_2(Tensor_Path)\n",
    "        Third_Block_Out = self.Block_3(Tensor_Path)\n",
    "        Fourth_Block_Out = self.Block_4(Tensor_Path)\n",
    "        \n",
    "        Concatenated_Outputs = torch.cat([First_Block_Out,Second_Block_Out, Third_Block_Out, Fourth_Block_Out], dim=1) #dim=1 because we want to concatenate in the depth dimension\n",
    "        return Concatenated_Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Inception Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Auxiliary_Classifier(nn.Module):\n",
    "    def __init__(self, In_Channels, Num_Classes):\n",
    "        super(Auxiliary_Classifier, self).__init__()\n",
    "        self.Adaptive_AvgPool = nn.AdaptiveAvgPool2d(output_size=(4, 4))\n",
    "        self.Conv = nn.Conv2d(in_channels= In_Channels, out_channels=128, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        self.Activ_Func = nn.ReLU()\n",
    "        self.FC_1 = nn.Linear(in_features=2048, out_features=1024) \n",
    "        self.DropOut = nn.Dropout(p=0.7) \n",
    "        self.FC_2 = nn.Linear(in_features=1024, out_features= Num_Classes)\n",
    "    \n",
    "    def forward(self, Tensor_Path):\n",
    "        Tensor_Path = self.Adaptive_AvgPool(Tensor_Path)\n",
    "        Tensor_Path = self.Conv(Tensor_Path)\n",
    "        Tensor_Path = self.Activ_Func(Tensor_Path)\n",
    "        Tensor_Path = torch.flatten(Tensor_Path, 1)\n",
    "        Tensor_Path = self.FC_1(Tensor_Path)\n",
    "        Tensor_Path = self.DropOut(Tensor_Path)\n",
    "        Tensor_Path = self.FC_2(Tensor_Path)\n",
    "        \n",
    "        return Tensor_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet_V1(nn.Module):\n",
    "    def __init__(self, Out_Classes):\n",
    "        super(InceptionNet_V1, self).__init__()\n",
    "        self.Conv_1 = ConvBlock(In_Channels=3, Out_Channels=64, Kernel_Size=(7,7), Stride=(2,2), Padding=(3,3))\n",
    "        self.MaxPool_1 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Conv_2 = ConvBlock(In_Channels=64, Out_Channels=64, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0))\n",
    "        self.Conv_3 = ConvBlock(In_Channels=64, Out_Channels=192, Kernel_Size=(3,3), Stride=(1,1), Padding=(1,1))\n",
    "        self.MaxPool_2 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Inception_3a = InceptionBlock(In_Channels=192, Num_Of_Filters_1x1=64, Num_Of_Filters_3x3=128\n",
    "                                          , Num_Of_Filters_5x5=32, Num_Of_Filters_3x3_Reduce=96, \n",
    "                                           Num_Of_Filters_5x5_Reduce=16, Pooling=32)\n",
    "        \n",
    "        self.Inception_3b = InceptionBlock(In_Channels=256, Num_Of_Filters_1x1=128, Num_Of_Filters_3x3=192\n",
    "                                          , Num_Of_Filters_5x5=96, Num_Of_Filters_3x3_Reduce=128, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=64)\n",
    "        \n",
    "        self.MaxPool_3 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Inception_4a = InceptionBlock(In_Channels=480, Num_Of_Filters_1x1=192, Num_Of_Filters_3x3=208\n",
    "                                          , Num_Of_Filters_5x5=48, Num_Of_Filters_3x3_Reduce=96, \n",
    "                                           Num_Of_Filters_5x5_Reduce=16, Pooling=64)\n",
    "        \n",
    "        self.Inception_4b = InceptionBlock(In_Channels=512, Num_Of_Filters_1x1=160, Num_Of_Filters_3x3=224\n",
    "                                          , Num_Of_Filters_5x5=64, Num_Of_Filters_3x3_Reduce=112, \n",
    "                                           Num_Of_Filters_5x5_Reduce=24, Pooling=64)\n",
    "        \n",
    "        \n",
    "        self.Inception_4c = InceptionBlock(In_Channels=512, Num_Of_Filters_1x1=128, Num_Of_Filters_3x3=256\n",
    "                                          , Num_Of_Filters_5x5=64, Num_Of_Filters_3x3_Reduce=128, \n",
    "                                           Num_Of_Filters_5x5_Reduce=24, Pooling=64)\n",
    "        \n",
    "       \n",
    "        self.Inception_4d = InceptionBlock(In_Channels=512, Num_Of_Filters_1x1=112, Num_Of_Filters_3x3=288\n",
    "                                          , Num_Of_Filters_5x5=64, Num_Of_Filters_3x3_Reduce=144, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=64) \n",
    "        \n",
    "        self.Inception_4e = InceptionBlock(In_Channels=528, Num_Of_Filters_1x1=256, Num_Of_Filters_3x3=320\n",
    "                                          , Num_Of_Filters_5x5=128, Num_Of_Filters_3x3_Reduce=160, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=128) \n",
    "        \n",
    "        self.MaxPool_4 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Inception_5a = InceptionBlock(In_Channels=832, Num_Of_Filters_1x1=256, Num_Of_Filters_3x3=320\n",
    "                                          , Num_Of_Filters_5x5=128, Num_Of_Filters_3x3_Reduce=160, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=128) \n",
    "        \n",
    "        self.Inception_5b = InceptionBlock(In_Channels=832, Num_Of_Filters_1x1=384, Num_Of_Filters_3x3=384\n",
    "                                          , Num_Of_Filters_5x5=128, Num_Of_Filters_3x3_Reduce=192, \n",
    "                                           Num_Of_Filters_5x5_Reduce=48, Pooling=128) \n",
    "        \n",
    "        self.AvgPool_1 = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.DropOut = nn.Dropout(p=0.4)\n",
    "        self.FC = nn.Linear(in_features=1024, out_features=Out_Classes)\n",
    "        \n",
    "        self.Auxiliary_4a = Auxiliary_Classifier(In_Channels=512, Num_Classes=Out_Classes)\n",
    "        self.Auxiliary_4d = Auxiliary_Classifier(In_Channels=528, Num_Classes=Out_Classes)\n",
    "        \n",
    "    def forward(self, Tensor_Path):\n",
    "        Tensor_Path = self.Conv_1(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_1(Tensor_Path)\n",
    "        Tensor_Path = self.Conv_2(Tensor_Path)\n",
    "        Tensor_Path = self.Conv_3(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_2(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_3a(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_3b(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_3(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4a(Tensor_Path)\n",
    "        Auxiliary_1 = self.Auxiliary_4a(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4b(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4c(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4d(Tensor_Path)\n",
    "        Auxiliary_2 = self.Auxiliary_4d(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4e(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_4(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_5a(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_5b(Tensor_Path)\n",
    "        Tensor_Path = self.AvgPool_1(Tensor_Path)\n",
    "        Tensor_Path = torch.flatten(Tensor_Path, 1)\n",
    "        Tensor_Path = self.DropOut(Tensor_Path)\n",
    "        Tensor_Path = self.FC(Tensor_Path)\n",
    "        \n",
    "        return Tensor_Path, Auxiliary_1, Auxiliary_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "InceptionNet_V1                          [51, 10]                  --\n",
       "├─ConvBlock: 1-1                         [51, 64, 112, 112]        --\n",
       "│    └─Conv2d: 2-1                       [51, 64, 112, 112]        9,472\n",
       "│    └─BatchNorm2d: 2-2                  [51, 64, 112, 112]        128\n",
       "│    └─ReLU: 2-3                         [51, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-2                         [51, 64, 56, 56]          --\n",
       "├─ConvBlock: 1-3                         [51, 64, 56, 56]          --\n",
       "│    └─Conv2d: 2-4                       [51, 64, 56, 56]          4,160\n",
       "│    └─BatchNorm2d: 2-5                  [51, 64, 56, 56]          128\n",
       "│    └─ReLU: 2-6                         [51, 64, 56, 56]          --\n",
       "├─ConvBlock: 1-4                         [51, 192, 56, 56]         --\n",
       "│    └─Conv2d: 2-7                       [51, 192, 56, 56]         110,784\n",
       "│    └─BatchNorm2d: 2-8                  [51, 192, 56, 56]         384\n",
       "│    └─ReLU: 2-9                         [51, 192, 56, 56]         --\n",
       "├─MaxPool2d: 1-5                         [51, 192, 28, 28]         --\n",
       "├─InceptionBlock: 1-6                    [51, 256, 28, 28]         --\n",
       "│    └─Sequential: 2-10                  [51, 64, 28, 28]          --\n",
       "│    │    └─ConvBlock: 3-1               [51, 64, 28, 28]          12,480\n",
       "│    └─Sequential: 2-11                  [51, 128, 28, 28]         --\n",
       "│    │    └─ConvBlock: 3-2               [51, 96, 28, 28]          18,720\n",
       "│    │    └─ConvBlock: 3-3               [51, 128, 28, 28]         110,976\n",
       "│    └─Sequential: 2-12                  [51, 32, 28, 28]          --\n",
       "│    │    └─ConvBlock: 3-4               [51, 16, 28, 28]          3,120\n",
       "│    │    └─ConvBlock: 3-5               [51, 32, 28, 28]          12,896\n",
       "│    └─Sequential: 2-13                  [51, 32, 28, 28]          --\n",
       "│    │    └─MaxPool2d: 3-6               [51, 192, 28, 28]         --\n",
       "│    │    └─ConvBlock: 3-7               [51, 32, 28, 28]          6,240\n",
       "├─InceptionBlock: 1-7                    [51, 480, 28, 28]         --\n",
       "│    └─Sequential: 2-14                  [51, 128, 28, 28]         --\n",
       "│    │    └─ConvBlock: 3-8               [51, 128, 28, 28]         33,152\n",
       "│    └─Sequential: 2-15                  [51, 192, 28, 28]         --\n",
       "│    │    └─ConvBlock: 3-9               [51, 128, 28, 28]         33,152\n",
       "│    │    └─ConvBlock: 3-10              [51, 192, 28, 28]         221,760\n",
       "│    └─Sequential: 2-16                  [51, 96, 28, 28]          --\n",
       "│    │    └─ConvBlock: 3-11              [51, 32, 28, 28]          8,288\n",
       "│    │    └─ConvBlock: 3-12              [51, 96, 28, 28]          77,088\n",
       "│    └─Sequential: 2-17                  [51, 64, 28, 28]          --\n",
       "│    │    └─MaxPool2d: 3-13              [51, 256, 28, 28]         --\n",
       "│    │    └─ConvBlock: 3-14              [51, 64, 28, 28]          16,576\n",
       "├─MaxPool2d: 1-8                         [51, 480, 14, 14]         --\n",
       "├─InceptionBlock: 1-9                    [51, 512, 14, 14]         --\n",
       "│    └─Sequential: 2-18                  [51, 192, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-15              [51, 192, 14, 14]         92,736\n",
       "│    └─Sequential: 2-19                  [51, 208, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-16              [51, 96, 14, 14]          46,368\n",
       "│    │    └─ConvBlock: 3-17              [51, 208, 14, 14]         180,336\n",
       "│    └─Sequential: 2-20                  [51, 48, 14, 14]          --\n",
       "│    │    └─ConvBlock: 3-18              [51, 16, 14, 14]          7,728\n",
       "│    │    └─ConvBlock: 3-19              [51, 48, 14, 14]          19,344\n",
       "│    └─Sequential: 2-21                  [51, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-20              [51, 480, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-21              [51, 64, 14, 14]          30,912\n",
       "├─Auxiliary_Classifier: 1-10             [51, 10]                  --\n",
       "│    └─AdaptiveAvgPool2d: 2-22           [51, 512, 4, 4]           --\n",
       "│    └─Conv2d: 2-23                      [51, 128, 4, 4]           65,664\n",
       "│    └─ReLU: 2-24                        [51, 128, 4, 4]           --\n",
       "│    └─Linear: 2-25                      [51, 1024]                2,098,176\n",
       "│    └─Dropout: 2-26                     [51, 1024]                --\n",
       "│    └─Linear: 2-27                      [51, 10]                  10,250\n",
       "├─InceptionBlock: 1-11                   [51, 512, 14, 14]         --\n",
       "│    └─Sequential: 2-28                  [51, 160, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-22              [51, 160, 14, 14]         82,400\n",
       "│    └─Sequential: 2-29                  [51, 224, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-23              [51, 112, 14, 14]         57,680\n",
       "│    │    └─ConvBlock: 3-24              [51, 224, 14, 14]         226,464\n",
       "│    └─Sequential: 2-30                  [51, 64, 14, 14]          --\n",
       "│    │    └─ConvBlock: 3-25              [51, 24, 14, 14]          12,360\n",
       "│    │    └─ConvBlock: 3-26              [51, 64, 14, 14]          38,592\n",
       "│    └─Sequential: 2-31                  [51, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-27              [51, 512, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-28              [51, 64, 14, 14]          32,960\n",
       "├─InceptionBlock: 1-12                   [51, 512, 14, 14]         --\n",
       "│    └─Sequential: 2-32                  [51, 128, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-29              [51, 128, 14, 14]         65,920\n",
       "│    └─Sequential: 2-33                  [51, 256, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-30              [51, 128, 14, 14]         65,920\n",
       "│    │    └─ConvBlock: 3-31              [51, 256, 14, 14]         295,680\n",
       "│    └─Sequential: 2-34                  [51, 64, 14, 14]          --\n",
       "│    │    └─ConvBlock: 3-32              [51, 24, 14, 14]          12,360\n",
       "│    │    └─ConvBlock: 3-33              [51, 64, 14, 14]          38,592\n",
       "│    └─Sequential: 2-35                  [51, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-34              [51, 512, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-35              [51, 64, 14, 14]          32,960\n",
       "├─InceptionBlock: 1-13                   [51, 528, 14, 14]         --\n",
       "│    └─Sequential: 2-36                  [51, 112, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-36              [51, 112, 14, 14]         57,680\n",
       "│    └─Sequential: 2-37                  [51, 288, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-37              [51, 144, 14, 14]         74,160\n",
       "│    │    └─ConvBlock: 3-38              [51, 288, 14, 14]         374,112\n",
       "│    └─Sequential: 2-38                  [51, 64, 14, 14]          --\n",
       "│    │    └─ConvBlock: 3-39              [51, 32, 14, 14]          16,480\n",
       "│    │    └─ConvBlock: 3-40              [51, 64, 14, 14]          51,392\n",
       "│    └─Sequential: 2-39                  [51, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-41              [51, 512, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-42              [51, 64, 14, 14]          32,960\n",
       "├─Auxiliary_Classifier: 1-14             [51, 10]                  --\n",
       "│    └─AdaptiveAvgPool2d: 2-40           [51, 528, 4, 4]           --\n",
       "│    └─Conv2d: 2-41                      [51, 128, 4, 4]           67,712\n",
       "│    └─ReLU: 2-42                        [51, 128, 4, 4]           --\n",
       "│    └─Linear: 2-43                      [51, 1024]                2,098,176\n",
       "│    └─Dropout: 2-44                     [51, 1024]                --\n",
       "│    └─Linear: 2-45                      [51, 10]                  10,250\n",
       "├─InceptionBlock: 1-15                   [51, 832, 14, 14]         --\n",
       "│    └─Sequential: 2-46                  [51, 256, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-43              [51, 256, 14, 14]         135,936\n",
       "│    └─Sequential: 2-47                  [51, 320, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-44              [51, 160, 14, 14]         84,960\n",
       "│    │    └─ConvBlock: 3-45              [51, 320, 14, 14]         461,760\n",
       "│    └─Sequential: 2-48                  [51, 128, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-46              [51, 32, 14, 14]          16,992\n",
       "│    │    └─ConvBlock: 3-47              [51, 128, 14, 14]         102,784\n",
       "│    └─Sequential: 2-49                  [51, 128, 14, 14]         --\n",
       "│    │    └─MaxPool2d: 3-48              [51, 528, 14, 14]         --\n",
       "│    │    └─ConvBlock: 3-49              [51, 128, 14, 14]         67,968\n",
       "├─MaxPool2d: 1-16                        [51, 832, 7, 7]           --\n",
       "├─InceptionBlock: 1-17                   [51, 832, 7, 7]           --\n",
       "│    └─Sequential: 2-50                  [51, 256, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-50              [51, 256, 7, 7]           213,760\n",
       "│    └─Sequential: 2-51                  [51, 320, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-51              [51, 160, 7, 7]           133,600\n",
       "│    │    └─ConvBlock: 3-52              [51, 320, 7, 7]           461,760\n",
       "│    └─Sequential: 2-52                  [51, 128, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-53              [51, 32, 7, 7]            26,720\n",
       "│    │    └─ConvBlock: 3-54              [51, 128, 7, 7]           102,784\n",
       "│    └─Sequential: 2-53                  [51, 128, 7, 7]           --\n",
       "│    │    └─MaxPool2d: 3-55              [51, 832, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-56              [51, 128, 7, 7]           106,880\n",
       "├─InceptionBlock: 1-18                   [51, 1024, 7, 7]          --\n",
       "│    └─Sequential: 2-54                  [51, 384, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-57              [51, 384, 7, 7]           320,640\n",
       "│    └─Sequential: 2-55                  [51, 384, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-58              [51, 192, 7, 7]           160,320\n",
       "│    │    └─ConvBlock: 3-59              [51, 384, 7, 7]           664,704\n",
       "│    └─Sequential: 2-56                  [51, 128, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-60              [51, 48, 7, 7]            40,080\n",
       "│    │    └─ConvBlock: 3-61              [51, 128, 7, 7]           153,984\n",
       "│    └─Sequential: 2-57                  [51, 128, 7, 7]           --\n",
       "│    │    └─MaxPool2d: 3-62              [51, 832, 7, 7]           --\n",
       "│    │    └─ConvBlock: 3-63              [51, 128, 7, 7]           106,880\n",
       "├─AdaptiveAvgPool2d: 1-19                [51, 1024, 1, 1]          --\n",
       "├─Dropout: 1-20                          [51, 1024]                --\n",
       "├─Linear: 1-21                           [51, 10]                  10,250\n",
       "==========================================================================================\n",
       "Total params: 10,348,590\n",
       "Trainable params: 10,348,590\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 81.15\n",
       "==========================================================================================\n",
       "Input size (MB): 30.71\n",
       "Forward/backward pass size (MB): 2635.07\n",
       "Params size (MB): 41.39\n",
       "Estimated Total Size (MB): 2707.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random_Tensor_4 = torch.randn(51, 3, 224, 224) # Санамсаргүй байдлаар Тенсор үүсгэж моделыг шалгах нь\n",
    "Network_Outputs = InceptionNet_V1(Out_Classes=10)\n",
    "Model_Summary(Network_Outputs, Random_Tensor_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Validate_Model(Model, Train_Loader, Val_Loader, Num_Of_Train_Samples, Num_Of_Val_Samples, Criterion,Optimizer, Num_Epochs):\n",
    "     \n",
    "    Train_Loss_History = []\n",
    "    Train_Accuracy_History = []\n",
    "    Val_Loss_History = []\n",
    "    Val_Accuracy_History = []\n",
    "    for epoch in tqdm(range(Num_Epochs)):\n",
    "        Num_Of_Predicted_Correctly = 0\n",
    "        Train_Cummulative_Loss = 0 \n",
    "        for batch_samples,targets in Train_Loader:\n",
    "            batch_samples = batch_samples.to(device=Device)\n",
    "            targets = targets.to(device=Device)\n",
    "            \n",
    "            Network_Predictions, Aux_1_Predictions, Aux_2_Predictions = Model(batch_samples)\n",
    "            \n",
    "            Network_Loss = Criterion(Network_Predictions, targets)\n",
    "            Aux_1_Loss = Criterion(Aux_1_Predictions, targets)\n",
    "            Aux_2_Loss = Criterion(Aux_2_Predictions, targets)\n",
    "            \n",
    "            Main_Loss = Network_Loss + (0.3 * Aux_1_Loss) + (0.3 * Aux_2_Loss)\n",
    "            \n",
    "            Optimizer.zero_grad()\n",
    "            Main_Loss.backward()\n",
    "            Optimizer.step()\n",
    "            \n",
    "            _, Train_Samples_Predictions = Network_Predictions.max(1)\n",
    "            Train_Samples_Predictions = Train_Samples_Predictions.to(device=Device)\n",
    "            Num_Of_Predicted_Correctly += (Train_Samples_Predictions == targets).float().sum().item()\n",
    "            Train_Cummulative_Loss += Main_Loss.data.item() * batch_samples.shape[0]\n",
    "            \n",
    "        Train_Cummulative_Loss /= Num_Of_Train_Samples\n",
    "        Train_Loss_History.append(Train_Cummulative_Loss)\n",
    "        Train_Accuracy = Num_Of_Predicted_Correctly / Num_Of_Train_Samples\n",
    "        Train_Accuracy_History.append(Train_Accuracy)\n",
    "    \n",
    "    \n",
    "        Num_Of_Predicted_Correctly = 0\n",
    "        with torch.no_grad(): \n",
    "            Val_Cummulative_Loss = 0\n",
    "            for batch_samples,targets in Val_Loader:\n",
    "                batch_samples = batch_samples.to(device=Device)\n",
    "                targets = targets.to(device=Device)\n",
    "\n",
    "                Network_Predictions, Aux_1_Predictions, Aux_2_Predictions = Model(batch_samples)\n",
    "\n",
    "                Network_Loss = Criterion(Network_Predictions, targets)\n",
    "                Aux_1_Loss = Criterion(Aux_1_Predictions, targets)\n",
    "                Aux_2_Loss = Criterion(Aux_2_Predictions, targets)\n",
    "\n",
    "                Main_Loss = Network_Loss + (0.3 * Aux_1_Loss) + (0.3 * Aux_2_Loss)\n",
    "\n",
    "                _, Val_Samples_Predictions = Network_Predictions.max(1)\n",
    "                Val_Samples_Predictions = Val_Samples_Predictions.to(device=Device)\n",
    "                Num_Of_Predicted_Correctly += (Val_Samples_Predictions == targets).float().sum().item()\n",
    "                Val_Cummulative_Loss += Main_Loss.data.item() * batch_samples.shape[0]\n",
    "            \n",
    "            Val_Cummulative_Loss /= Num_Of_Val_Samples\n",
    "            Val_Loss_History.append(Val_Cummulative_Loss)\n",
    "            Val_Accuracy = Num_Of_Predicted_Correctly / Num_Of_Val_Samples\n",
    "            Val_Accuracy_History.append(Val_Accuracy)\n",
    "\n",
    "\n",
    "            print(\"Epoch:\", epoch, \" \", \"train-loss:\", Train_Cummulative_Loss \n",
    "                 , \" \", \"train-acc:\", Train_Accuracy, \" \", \"val-loss:\", Val_Cummulative_Loss, \" \",\n",
    "                 \"val-acc:\", Val_Accuracy)\n",
    "    torch.save(Model.state_dict(), \"InceptionNet_Model\")\n",
    "    return Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_Image(Sample, Target):\n",
    "    # this dictionary is to convert target index to its actual name when plotting image\n",
    "    CIFAR_Targets= {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
    "                   5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "    plt.imshow(Sample)\n",
    "    plt.title(CIFAR_Targets[Target])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Image shape of a random sample image : (3, 32, 32)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def CIFAR_DataLoader(Num_Of_Train_Samples, Num_Of_Val_Samples, Batch_Size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    CIFAR_Train_set = datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "    CIFAR_Test_set = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "    \n",
    "   \n",
    "    Train_Samples, Validation_Samples = random_split(CIFAR_Train_set, (Num_Of_Train_Samples, Num_Of_Val_Samples))\n",
    "    \n",
    "   \n",
    "    Train_Loader = DataLoader(Train_Samples,batch_size= Batch_Size, shuffle=True)\n",
    "    Val_Loader = DataLoader(Validation_Samples,batch_size= Batch_Size, shuffle=True)\n",
    "    Test_Loader = DataLoader(CIFAR_Test_set, batch_size= Batch_Size, shuffle=True)\n",
    "    print(\"Image shape of a random sample image : {}\".format(Train_Samples[0][0].numpy().shape), end = '\\n\\n')\n",
    "\n",
    "    Random_Sample_Index = np.random.randint(0,Num_Of_Train_Samples+Num_Of_Val_Samples)\n",
    "    Sample = np.array(CIFAR_Train_set.data)[Random_Sample_Index]\n",
    "    Target = np.array(CIFAR_Train_set.targets)[Random_Sample_Index]\n",
    "    Show_Image(Sample, Target)\n",
    "    \n",
    "    return Train_Loader, Val_Loader, Test_Loader\n",
    "\n",
    "Train_Set, Validation_Set, Test_Set = CIFAR_DataLoader(Num_Of_Train_Samples=45000,Num_Of_Val_Samples= 5000, Batch_Size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Model_History(Train_Accuracy_History , Val_Accuracy_History, Train_Loss_History, Val_Loss_History):\n",
    "    # plot Accuracy\n",
    "    plt.plot(Train_Accuracy_History, marker='o')\n",
    "    plt.plot(Val_Accuracy_History, marker='o')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot Loss\n",
    "    plt.plot(Train_Loss_History, marker='8')\n",
    "    plt.plot(Val_Loss_History, marker='8')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m     Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History \u001b[38;5;241m=\u001b[39m Train_Validate_Model(Model \u001b[38;5;241m=\u001b[39m Inception_Model, Train_Loader \u001b[38;5;241m=\u001b[39m Train_Set,Val_Loader \u001b[38;5;241m=\u001b[39m Validation_Set,Num_Of_Train_Samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m45000\u001b[39m,\n\u001b[0;32m      6\u001b[0m                          Num_Of_Val_Samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m,Criterion \u001b[38;5;241m=\u001b[39m Cross_Entropy_Criterion,Optimizer \u001b[38;5;241m=\u001b[39m Adam_Optimizer,Num_Epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      8\u001b[0m     Plot_Model_History( Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mPropagate_Network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m, in \u001b[0;36mPropagate_Network\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m Cross_Entropy_Criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      4\u001b[0m Adam_Optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(Inception_Model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History \u001b[38;5;241m=\u001b[39m \u001b[43mTrain_Validate_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mInception_Model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrain_Loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTrain_Set\u001b[49m\u001b[43m,\u001b[49m\u001b[43mVal_Loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mValidation_Set\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNum_Of_Train_Samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m45000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mNum_Of_Val_Samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mCriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCross_Entropy_Criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mOptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAdam_Optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNum_Epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m Plot_Model_History( Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History)\n",
      "Cell \u001b[1;32mIn[44], line 23\u001b[0m, in \u001b[0;36mTrain_Validate_Model\u001b[1;34m(Model, Train_Loader, Val_Loader, Num_Of_Train_Samples, Num_Of_Val_Samples, Criterion, Optimizer, Num_Epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m Main_Loss \u001b[38;5;241m=\u001b[39m Network_Loss \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.3\u001b[39m \u001b[38;5;241m*\u001b[39m Aux_1_Loss) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.3\u001b[39m \u001b[38;5;241m*\u001b[39m Aux_2_Loss)\n\u001b[0;32m     22\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 23\u001b[0m \u001b[43mMain_Loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m _, Train_Samples_Predictions \u001b[38;5;241m=\u001b[39m Network_Predictions\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ojro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ojro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Propagate_Network():\n",
    "    Inception_Model = InceptionNet_V1(Out_Classes=10).to(device=Device)\n",
    "    Cross_Entropy_Criterion = nn.CrossEntropyLoss()\n",
    "    Adam_Optimizer = optim.Adam(Inception_Model.parameters(), lr=0.001)\n",
    "    Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History = Train_Validate_Model(Model = Inception_Model, Train_Loader = Train_Set,Val_Loader = Validation_Set,Num_Of_Train_Samples = 45000,\n",
    "                         Num_Of_Val_Samples = 5000,Criterion = Cross_Entropy_Criterion,Optimizer = Adam_Optimizer,Num_Epochs = 100)\n",
    "    \n",
    "    Plot_Model_History( Train_Accuracy_History, Val_Accuracy_History, Train_Loss_History, Val_Loss_History)\n",
    "Propagate_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
